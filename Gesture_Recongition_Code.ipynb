{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tracyuniverse/SkyScroll-Website/blob/main/Gesture_Recongition_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gMAtRN6x1C1",
        "outputId": "fc46f77c-d0a4-4def-ea98-1e9611fcb180"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gY68MCU13Glu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fdbd40a-024a-4e8f-e1c2-30499374dde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SkyScroll'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 204 (delta 66), reused 48 (delta 48), pack-reused 110 (from 1)\u001b[K\n",
            "Receiving objects: 100% (204/204), 3.06 MiB | 9.45 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models, datasets\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "!git clone https://github.com/tarashakhurana/SkyScroll"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf SkyScroll/.git"
      ],
      "metadata": {
        "id": "cxrxiq2myA59"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code to delete folders\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "output_base = '/content/GEI_Output'\n",
        "\n",
        "# Delete the folder if it exists\n",
        "if os.path.exists(output_base):\n",
        "    shutil.rmtree(output_base)\n",
        "    print(f\"Deleted existing folder: {output_base}\")\n",
        "else:\n",
        "    print(f\"Folder does not exist: {output_base}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czkWGnU0BT5X",
        "outputId": "e05c80ad-ef23-4a8f-83fb-6fae3f4d894d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder does not exist: /content/GEI_Output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gei_weighted(video_path, threshold=0.1,  max_brightness=0.85, min_brightness=0.2, decay_power=3.0 ):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return None\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "    result_image = np.zeros((frame_height, frame_width), dtype=np.float32)\n",
        "    has_written = np.zeros_like(result_image, dtype=bool)\n",
        "\n",
        "    frame_idx = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        gray = gray.astype(np.float32) / 255.0\n",
        "\n",
        "        # Detect new hand presence\n",
        "        mask = (gray > threshold) & (~has_written)\n",
        "\n",
        "        # Sharper brightness decay (exponential-like)\n",
        "        progress = frame_idx / max(total_frames - 1, 1)\n",
        "        decay = (1.0 - progress) ** decay_power  # faster dropoff\n",
        "        brightness = min_brightness + (max_brightness - min_brightness) * decay\n",
        "\n",
        "        result_image[mask] = brightness\n",
        "        has_written[mask] = True\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Display image\n",
        "    result_display = (result_image * 255).astype(np.uint8)\n",
        "\n",
        "    # plt.imshow(result_display, cmap='gray')\n",
        "    # # plt.title(\"Fast Fading Motion Trail (Early Emphasis, Sharp Drop)\")\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    return result_display\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "generate_gei_weighted('/content/SkyScroll/zoom_in_1.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp4K4E-TT3Q-",
        "outputId": "781f2634-c47d-450f-9f8c-5a2f7b093c01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate and process all files and sort them under Processed_videos\n",
        "\n",
        "# Paths\n",
        "input_folder = '/content/SkyScroll'\n",
        "output_folder = '/content/GEI_Output'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "def generate_gei(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        gray = gray.astype(np.float32)\n",
        "        frames.append(gray)\n",
        "\n",
        "    cap.release()\n",
        "    if not frames:\n",
        "        return None\n",
        "\n",
        "    frames_np = np.stack(frames, axis=0)\n",
        "    gei = np.mean(frames_np, axis=0)\n",
        "    gei = cv2.normalize(gei, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    return gei.astype(np.uint8)\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    file_path = os.path.join(input_folder, filename)\n",
        "\n",
        "    if os.path.isfile(file_path) and filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "        parts = filename.split('_')\n",
        "        class_label = '_'.join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
        "\n",
        "        class_folder = os.path.join(output_folder, class_label)\n",
        "        os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "        gei_image = generate_gei_weighted(file_path)\n",
        "        if gei_image is not None:\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "            output_filename = f\"processed_{base_name}.png\"\n",
        "            output_path = os.path.join(class_folder, output_filename)\n",
        "            cv2.imwrite(output_path, gei_image)\n",
        "            # print(f\"✅ Saved GEI: {output_path}\")\n",
        "        # else:\n",
        "            # print(f\"⚠️ Failed to generate GEI for {filename}\")"
      ],
      "metadata": {
        "id": "TNXEiWSmixR7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING CODE\n",
        "\n",
        "\n",
        "#train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "#train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "#val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
        "#val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "vvld1Jc5xzIi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_image_paths = []\n",
        "for root, _, files in os.walk('/content/GEI_Output/'):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "            all_image_paths.append(os.path.join(root, file))\n",
        "\n",
        "# Check if we have enough images\n",
        "if len(all_image_paths) < 10:\n",
        "    print(f\"Warning: Only found {len(all_image_paths)} images. Need at least 10 for the split.\")\n",
        "else:\n",
        "    # Perform the split\n",
        "    # We use stratify=None here as we are splitting file paths, not necessarily ensuring class balance in the split\n",
        "    train_paths, val_paths = train_test_split(all_image_paths, test_size=0.3, random_state=42)\n",
        "\n",
        "    print(f\"Total images found: {len(all_image_paths)}\")\n",
        "    print(f\"Training images: {len(train_paths)}\")\n",
        "    print(f\"Validation images: {len(val_paths)}\")\n",
        "\n",
        "    # To use these paths with DataLoader, you would typically:\n",
        "    # 1. Create new temporary directories for train and validation data.\n",
        "    # 2. Copy the respective files into those directories, maintaining the class structure.\n",
        "    # 3. Point datasets.ImageFolder to these new train and validation directories.\n",
        "\n",
        "    # Example of creating new directories and copying (Simplified):\n",
        "    train_dir = '/content/GEI_Output_Split/train'\n",
        "    val_dir = '/content/GEI_Output_Split/val'\n",
        "\n",
        "    # Clean up previous splits if they exist\n",
        "    if os.path.exists(train_dir):\n",
        "        shutil.rmtree(train_dir)\n",
        "    if os.path.exists(val_dir):\n",
        "        shutil.rmtree(val_dir)\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    def copy_files(file_list, destination_base):\n",
        "        for file_path in file_list:\n",
        "            # Determine the original class label from the path\n",
        "            relative_path = os.path.relpath(file_path, '/content/GEI_Output/')\n",
        "            class_label = relative_path.split(os.sep)[0]\n",
        "            dest_class_dir = os.path.join(destination_base, class_label)\n",
        "            os.makedirs(dest_class_dir, exist_ok=True)\n",
        "            shutil.copy(file_path, dest_class_dir)\n",
        "\n",
        "    print(\"Copying training files...\")\n",
        "    copy_files(train_paths, train_dir)\n",
        "    print(\"Copying validation files...\")\n",
        "    copy_files(val_paths, val_dir)\n",
        "    print(\"File copying complete.\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize((150, 150)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Now, create ImageFolder datasets using the new split directories\n",
        "    train_data_split = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "    val_data_split = datasets.ImageFolder(root=val_dir, transform=transform)\n",
        "\n",
        "    # Create DataLoaders from the split datasets\n",
        "    train_loader = DataLoader(train_data_split, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_data_split, batch_size=32, shuffle=False)\n",
        "\n",
        "    print(f\"Train DataLoader has {len(train_loader.dataset)} images.\")\n",
        "    print(f\"Validation DataLoader has {len(val_loader.dataset)} images.\")\n",
        "\n",
        "    # You can now use train_loader and val_loader for training and validation\n"
      ],
      "metadata": {
        "id": "T_JOfyg4TOOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292911e7-846b-4450-da95-484b785b3f73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 60\n",
            "Training images: 42\n",
            "Validation images: 18\n",
            "Copying training files...\n",
            "Copying validation files...\n",
            "File copying complete.\n",
            "Train DataLoader has 42 images.\n",
            "Validation DataLoader has 18 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Changed the output size of the final linear layer to 3 for 3 classes\n",
        "        self.fc1 = nn.Linear(32 * 75 * 75, 512)\n",
        "        self.fc2 = nn.Linear(512, 6) # Output 6 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 32 * 75 * 75)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # Removed sigmoid activation for multi-class output with CrossEntropyLoss\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "x2JW8AClyGqF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = CNN()\n",
        "num_classes = len(train_data_split.classes)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "# Changed criterion to CrossEntropyLoss for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Reh3dW7fyMCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4ae720-5a49-4cbe-847c-f38269b50d24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 17 # Define the number of epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in val_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        print(\"Unique label values:\", torch.unique(labels))\n",
        "        print(\"Label range:\", labels.min(), labels.max())\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "z9ndK4m_yNWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65970ea4-d983-497c-ba8f-56756ffcb06c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 1/17, Loss: 2.1725\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 2/17, Loss: 0.1971\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 3/17, Loss: 0.0338\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 4/17, Loss: 0.0044\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 5/17, Loss: 0.0026\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 6/17, Loss: 0.0018\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 7/17, Loss: 0.0013\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 8/17, Loss: 0.0010\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 9/17, Loss: 0.0007\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 10/17, Loss: 0.0005\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 11/17, Loss: 0.0004\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 12/17, Loss: 0.0004\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 13/17, Loss: 0.0003\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 14/17, Loss: 0.0003\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 15/17, Loss: 0.0003\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 16/17, Loss: 0.0003\n",
            "Unique label values: tensor([0, 1, 2, 3, 4])\n",
            "Label range: tensor(0) tensor(4)\n",
            "Epoch 17/17, Loss: 0.0003\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the validation data: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "gJcMb5RGyO6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5955d4-38fc-4049-f1af-04fd6ab8131f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the validation data: 94.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "862987c6"
      },
      "source": [
        "# Task\n",
        "Generate GEIs for all video files in the \"SkyScroll\" directory and save them in separate folders for each class within that directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4ab91c"
      },
      "source": [
        "## Identify video files\n",
        "\n",
        "### Subtask:\n",
        "Identify all video files within the `SkyScroll` directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62356828"
      },
      "source": [
        "**Reasoning**:\n",
        "Identify all video files within the `SkyScroll` directory by listing files and checking for video extensions.\n",
        "\n"
      ]
    }
  ]
}